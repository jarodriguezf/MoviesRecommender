{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from automation_process_dataV1 import united_functions\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_parquet('../../data/raw/data_model/dataset_process_trainV1.0.parquet')#Carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = united_functions(df_)# Script de procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15839932 entries, 0 to 15839931\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   userId       int64  \n",
      " 1   movieId      int64  \n",
      " 2   rating       float64\n",
      " 3   title        object \n",
      " 4   genres       object \n",
      " 5   tagId        int64  \n",
      " 6   relevance    float64\n",
      " 7   tag          object \n",
      " 8   year_rate    int32  \n",
      " 9   month_rate   int32  \n",
      " 10  day_rate     int32  \n",
      " 11  launch_year  int32  \n",
      " 12  len_title    int64  \n",
      " 13  main_genre   object \n",
      " 14  valoration   object \n",
      "dtypes: float64(2), int32(4), int64(4), object(5)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numerics_columns(X):\n",
    "    numeric_columns = X.select_dtypes(include='number')\n",
    "    return numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categorical_columns(X):\n",
    "    categorical_columns = X.select_dtypes(exclude='number')\n",
    "    return categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificacion de variables numericas\n",
    "def numeric_normalize(X):\n",
    "    # Extraemos las columnas numéricas\n",
    "    numeric_columns=extract_numerics_columns(X)\n",
    "\n",
    "    # Creamos un MinMaxScaler y normalizamos las columnas numéricas\n",
    "    normalizer = StandardScaler()\n",
    "    normalized_numeric_columns = normalizer.fit_transform(numeric_columns)\n",
    "\n",
    "    # Retorna ndarray \n",
    "    return normalized_numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificacion de variables categoricas\n",
    "def categorical_encoder(X):\n",
    "    # Extraemos las columnas categoricas\n",
    "    categorical_columns=extract_categorical_columns(X)\n",
    "    categorical_columns_encoded = {}\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        # Utilizamos pd.Categorical para realizar la codificación\n",
    "        encoded_column = pd.Categorical(X[col]).codes\n",
    "        # Almacenamos la columna codificada en el diccionario\n",
    "        categorical_columns_encoded[col] = encoded_column\n",
    "    return categorical_columns_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos la codificacion de los valores numericos y categoricos\n",
    "def concat_types(X):\n",
    "    numeric=numeric_normalize(X)\n",
    "    categorical=categorical_encoder(X)\n",
    "    \n",
    "    return np.concatenate((numeric,categorical), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed=concat_types(df_processed) # Concatenacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion del modelo autoencoder V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a tensor la matriz de numpy\n",
    "X_processed_tensor = tf.convert_to_tensor(X_processed, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar variables que ya no van a ser utilizadas (liberamos memoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_processed\n",
    "del X_processed\n",
    "del df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atamos pesos entre capas con keras (capa personalizada)\n",
    "class DenseTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, dense_layer, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense_layer = dense_layer\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.biases = self.add_weight(name='bias',\n",
    "                                      shape=self.dense_layer.input_shape[-1],\n",
    "                                      initializer='zeros')\n",
    "        super().build(batch_input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = tf.matmul(inputs, self.dense_layer.weights[0], transpose_b=True)\n",
    "        return self.activation(Z + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el autocodificador creando su estructura y red\n",
    "dense_1 = tf.keras.layers.Dense(100, activation='relu')\n",
    "dense_2 = tf.keras.layers.Dense(30, activation='relu')\n",
    "\n",
    "tied_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    dense_1,\n",
    "    dense_2\n",
    "])\n",
    "\n",
    "tied_decoder = tf.keras.Sequential([\n",
    "    DenseTranspose(dense_2, activation='relu'),\n",
    "    DenseTranspose(dense_1, activation='linear'),\n",
    "    tf.keras.layers.Reshape((15,))\n",
    "])\n",
    "\n",
    "tied_ae = tf.keras.Sequential([tied_encoder, tied_decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila el modelo autoencoder\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "tied_ae.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los datos de entrada tienen el tamaño (15839932, 15)\n",
    "# Entrenar el modelo autoencoder\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "tied_ae.fit(X_processed_tensor, X_processed_tensor, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_ae_V1.0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_ae_V1.0\\assets\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo en formato SavedModel\n",
    "tied_ae.save('models/model_ae_V1.0', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:1113: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo desde el formato SavedModel\n",
    "tied_ae = tf.keras.models.load_model('models/model_ae_V1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecir el modelo entrenado con el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet('../../data/raw/data_model/dataset_process_testV1.0.parquet')#Carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_test = united_functions(df_test)# Script de procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed_test=concat_types(df_processed_test) # Concatenacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a tensor la matriz de numpy\n",
    "X_processed_test_tensor = tf.convert_to_tensor(X_processed_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jarod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3960129/3960129 [==============================] - 5233s 1ms/step - loss: 0.8478\n",
      "Pérdida en el conjunto de prueba: 0.8477622866630554\n"
     ]
    }
   ],
   "source": [
    "# Prediccion (Loss)\n",
    "test_loss = tied_ae.evaluate(X_processed_test_tensor, X_processed_test_tensor, batch_size=1)\n",
    "print(f\"Pérdida en el conjunto de prueba: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error obtenido es de 0.84, mas bajo que la Baseline (1.07)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
